{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdb89b-0543-46cf-86ca-af152a1f1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f20cee-fdd0-4cb4-b425-f08d96fea6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_job_api_response(job_json):\n",
    "    title = job_json['PositionTitle']\n",
    "    agency = job_json['OrganizationName']\n",
    "\n",
    "    desc = job_json['UserArea']['Details'].get('JobSummary', '')\n",
    "    duties = job_json['UserArea']['Details'].get('MajorDuties', '')\n",
    "\n",
    "    # FIX: if JobSummary or MajorDuties are lists, join them\n",
    "    if isinstance(desc, list):\n",
    "        desc = ' '.join(desc)\n",
    "    if isinstance(duties, list):\n",
    "        duties = ' '.join(duties)\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        'JobTitle': title,\n",
    "        'Agency': agency,\n",
    "        'JobDescription': desc,\n",
    "        'KeyDuties': duties\n",
    "    }])\n",
    "\n",
    "    # Combined text\n",
    "    df['CombinedText'] = (df['JobDescription'].fillna('') + ' ' + df['KeyDuties'].fillna('')).str.lower()\n",
    "\n",
    "    # IsDataBuyer\n",
    "    related_phrases = [\n",
    "        \"data acquisition\", \"data procurement\", \"procure data\", \"purchase data\",\n",
    "        \"buy data\", \"acquiring data\", \"data sourcing\", \"data licensing\", \n",
    "        \"external data acquisition\", \"third-party data\", \"data vendor\", \n",
    "        \"data provider\", \"data contracts\", \"contracting data\", \"data subscriptions\",\n",
    "        \"vendor management\", \"external data\", \"commercial data\"\n",
    "    ]\n",
    "    pattern = '|'.join([re.escape(phrase) for phrase in related_phrases])\n",
    "    df['IsDataBuyer'] = df['CombinedText'].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "    # FuzzyMatchedPhrase and IsFuzzyMatch\n",
    "    signal_phrases = [\n",
    "        \"data acquisition\", \"data procurement\", \"procure data\", \"purchase data\",\n",
    "        \"buy data\", \"acquiring data\", \"data sourcing\", \"data licensing\", \n",
    "        \"external data\", \"third-party data\", \"data vendor\", \n",
    "        \"data provider\", \"data contracts\", \"contracting data\", \"data subscriptions\",\n",
    "        \"vendor management\", \"commercial data\", \"data assets\", \"data commercialization\",\n",
    "        \"procurement of data\", \"external data sources\", \"data aggregators\",\n",
    "        \"data monetization\", \"sourcing external data\", \"partner data\", \"data purchasing agreements\",\n",
    "        \"data ingestion\", \"subscription data\", \"data acquisition strategy\", \"data buying\",\n",
    "        \"external datasets\", \"external partnerships\", \"data sharing agreements\",\n",
    "        \"data acquisition channels\", \"third-party data sources\", \"sourcing data providers\",\n",
    "        \"managing data vendors\", \"data reseller\", \"external data vendors\", \"contracted data\"\n",
    "    ]\n",
    "\n",
    "    def fuzzy_match_phrases(text, phrases, threshold=80):\n",
    "        for phrase in phrases:\n",
    "            score = fuzz.partial_ratio(phrase.lower(), text.lower())\n",
    "            if score >= threshold:\n",
    "                return phrase\n",
    "        return None\n",
    "\n",
    "    df['FuzzyMatchedPhrase'] = df['CombinedText'].apply(lambda x: fuzzy_match_phrases(x, signal_phrases))\n",
    "    df['IsFuzzyMatch'] = df['FuzzyMatchedPhrase'].notnull().astype(int)\n",
    "\n",
    "    # IsLikelyDataBuyer\n",
    "    df['IsLikelyDataBuyer'] = ((df['IsDataBuyer'] == 1) | (df['IsFuzzyMatch'] == 1)).astype(int)\n",
    "\n",
    "    # AgencySize\n",
    "    large_agencies = [\n",
    "        \"Department of Defense\", \"Department of Veterans Affairs\", \"Department of the Treasury\",\n",
    "        \"Department of Homeland Security\", \"Department of Health and Human Services\",\n",
    "        \"Department of Justice\", \"Department of the Army\"\n",
    "    ]\n",
    "    medium_agencies = [\n",
    "        \"Department of Transportation\", \"Department of Commerce\", \"Department of Agriculture\",\n",
    "        \"Department of Energy\", \"Department of the Interior\", \"National Aeronautics and Space Administration\"\n",
    "    ]\n",
    "\n",
    "    def classify_agency_size(agency):\n",
    "        if agency in large_agencies:\n",
    "            return 'Large'\n",
    "        elif agency in medium_agencies:\n",
    "            return 'Medium'\n",
    "        else:\n",
    "            return 'Small'\n",
    "\n",
    "    df['AgencySize'] = df['Agency'].apply(classify_agency_size).fillna('Unknown')\n",
    "\n",
    "    # Industry classifier\n",
    "    def classify_industry(row):\n",
    "        text = f\"{row['JobTitle']} {row['Agency']}\".lower()\n",
    "        if any(x in text for x in ['finance', 'financial', 'account', 'budget']):\n",
    "            return 'Finance'\n",
    "        elif any(x in text for x in ['marketing', 'communications', 'advertising']):\n",
    "            return 'Marketing'\n",
    "        elif any(x in text for x in ['medical', 'pharmacy', 'nurse', 'health', 'clinical']):\n",
    "            return 'Medical'\n",
    "        elif any(x in text for x in ['cyber', 'security', 'information technology', 'it', 'data scientist', 'software', 'tech']):\n",
    "            return 'Security/Tech'\n",
    "        elif any(x in text for x in ['policy', 'regulation', 'legislative', 'analyst', 'compliance']):\n",
    "            return 'Policy'\n",
    "        else:\n",
    "            return 'Other'\n",
    "\n",
    "    df['Industry'] = df.apply(classify_industry, axis=1).fillna('Other')\n",
    "\n",
    "    # IsSeniorRole\n",
    "    senior_keywords = ['senior', 'lead', 'chief', 'principal', 'director', 'head']\n",
    "    df['IsSeniorRole'] = df['JobTitle'].str.lower().str.contains('|'.join(senior_keywords), na=False)\n",
    "\n",
    "    # IsExplicitDataJob\n",
    "    data_keywords = ['data', 'analyst', 'scientist', 'analytics', 'it', 'information', 'statistician', 'intelligence']\n",
    "    df['IsExplicitDataJob'] = df['JobTitle'].str.lower().str.contains('|'.join(data_keywords), na=False).astype(int)\n",
    "\n",
    "    # Use Cases\n",
    "    use_case_keywords = {\n",
    "        'Fraud': ['fraud', 'eligibility', 'verification', 'audit', 'compliance'],\n",
    "        'Sentiment': ['sentiment', 'public opinion', 'media monitoring', 'engagement', 'communication'],\n",
    "        'PatientMatching': ['patient match', 'interoperability', 'record linkage', 'ehr', 'health record'],\n",
    "        'AdTargeting': ['audience segmentation', 'targeting', 'ad performance', 'campaign data']\n",
    "    }\n",
    "    for use_case, keywords in use_case_keywords.items():\n",
    "        pattern = '|'.join(keywords)\n",
    "        df[f'UseCase_{use_case}'] = df['CombinedText'].str.lower().str.contains(pattern, na=False).astype(int)\n",
    "\n",
    "    # IsGeneralistRole\n",
    "    generalist_titles = [\n",
    "        'Contract Specialist', 'Grants Officer', 'Grants Specialist', 'Budget Officer',\n",
    "        'Administrative Officer', 'Operations Coordinator', 'Program Coordinator',\n",
    "        'Project Coordinator', 'Procurement Specialist', 'Procurement Analyst',\n",
    "        'Communications Specialist', 'Public Affairs Officer', 'Public Information Officer',\n",
    "        'Community Outreach Coordinator', 'Health IT Coordinator', 'Program Specialist',\n",
    "        'Program Manager', 'Business Operations Specialist'\n",
    "    ]\n",
    "\n",
    "    def is_generalist(title, threshold=65):\n",
    "        match, score, _ = process.extractOne(title, generalist_titles, scorer=fuzz.partial_ratio)\n",
    "        return score >= threshold\n",
    "\n",
    "    df['IsGeneralistRole'] = df['JobTitle'].apply(lambda x: is_generalist(str(x)))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a88e14-730d-4a4a-98c7-c71567bab90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_score_job(job_id, api_key, email, pipeline_path=\"nlp_pipeline_with_smote.joblib\"):\n",
    "    headers = {\n",
    "        \"User-Agent\": email,\n",
    "        \"Authorization-Key\": api_key\n",
    "    }\n",
    "\n",
    "    url = f\"https://data.usajobs.gov/api/Search?Keyword={job_id}\"\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to fetch job ID {job_id}: {response.status_code}\")\n",
    "\n",
    "    job_data = response.json()['SearchResult']['SearchResultItems'][0]['MatchedObjectDescriptor']\n",
    "    df_processed = preprocess_job_api_response(job_data)\n",
    "\n",
    "    pipeline = joblib.load(pipeline_path)\n",
    "    X = pipeline.named_steps['preprocessor'].transform(df_processed)\n",
    "    score = pipeline.named_steps['classifier'].predict_proba(X)[0][1]\n",
    "\n",
    "    return {\n",
    "        \"data_buyer_score\": round(score, 4),\n",
    "        \"title\": job_data['PositionTitle'],\n",
    "        \"agency\": job_data['OrganizationName']\n",
    "        \n",
    "    }\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def batch_fetch_and_score_jobs(job_titles, api_key, email, pipeline_path=\"nlp_pipeline_with_smote.joblib\"):\n",
    "    results = []\n",
    "    for title in job_titles:\n",
    "        try:\n",
    "            search_results = search_job_ids_by_title(title, api_key, email, max_results=1)\n",
    "            if search_results:\n",
    "                job_id = search_results[0]['job_id']\n",
    "                scored = fetch_and_score_job(job_id, api_key, email, pipeline_path)\n",
    "                results.append(scored)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {title}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fe45f-653c-4b83-aa4c-3843e4ced37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_job_ids_by_title(position_title, api_key, email, max_results=10):\n",
    "    headers = {\n",
    "        \"User-Agent\": email,\n",
    "        \"Authorization-Key\": api_key\n",
    "    }\n",
    "\n",
    "    url = f\"https://data.usajobs.gov/api/Search\"\n",
    "\n",
    "    params = {\n",
    "        \"Keyword\": position_title,\n",
    "        \"ResultsPerPage\": max_results\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to search: {response.status_code}\")\n",
    "\n",
    "    jobs = response.json()['SearchResult']['SearchResultItems']\n",
    "    results = []\n",
    "    for job in jobs:\n",
    "        job_id = job['MatchedObjectDescriptor']['PositionID']\n",
    "        title = job['MatchedObjectDescriptor']['PositionTitle']\n",
    "        agency = job['MatchedObjectDescriptor']['OrganizationName']\n",
    "        results.append({\n",
    "            \"job_id\": job_id,\n",
    "            \"title\": title,\n",
    "            \"agency\": agency\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6e6338-f809-42db-b843-a95d9ecef12d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
